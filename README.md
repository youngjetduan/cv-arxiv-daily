[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.11.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#llm>LLM</a></li>
    <li><a href=#early-stopping>Early Stopping</a></li>
  </ol>
</details>

## LLM

|ID|Publish Date|Title|Authors|PDF|Code|Kimi|
|---|---|---|---|---|---|---|
| 1|**2024-11-14**|**Squeezed Attention: Accelerating Long Context Length LLM Inference**|Coleman Hooper et.al.|[2411.09688](http://arxiv.org/abs/2411.09688)|null|[Kimi](https://papers.cool/arxiv/2411.09688)|
| 2|**2024-11-14**|**Communication Compression for Tensor Parallel LLM Inference**|Jan Hansen-Palmus et.al.|[2411.09510](http://arxiv.org/abs/2411.09510)|null|[Kimi](https://papers.cool/arxiv/2411.09510)|
| 3|**2024-11-12**|**Towards Low-bit Communication for Tensor Parallel LLM Inference**|Harry Dong et.al.|[2411.07942](http://arxiv.org/abs/2411.07942)|null|[Kimi](https://papers.cool/arxiv/2411.07942)|
| 4|**2024-11-11**|**Anchor Attention, Small Cache: Code Generation with Large Language Models**|Xiangyu Zhang et.al.|[2411.06680](http://arxiv.org/abs/2411.06680)|null|[Kimi](https://papers.cool/arxiv/2411.06680)|
| 5|**2024-11-10**|**Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator**|Kazuki Fujii et.al.|[2411.06465](http://arxiv.org/abs/2411.06465)|null|[Kimi](https://papers.cool/arxiv/2411.06465)|
| 6|**2024-11-08**|**Balancing Pipeline Parallelism with Vocabulary Parallelism**|Man Tsung Yeung et.al.|[2411.05288](http://arxiv.org/abs/2411.05288)|**[link](https://github.com/sail-sg/vocabularyparallelism)**|[Kimi](https://papers.cool/arxiv/2411.05288)|
| 7|**2024-11-07**|**BitNet a4.8: 4-bit Activations for 1-bit LLMs**|Hongyu Wang et.al.|[2411.04965](http://arxiv.org/abs/2411.04965)|null|[Kimi](https://papers.cool/arxiv/2411.04965)|
| 8|**2024-11-06**|**Stepping Forward on the Last Mile**|Chen Feng et.al.|[2411.04036](http://arxiv.org/abs/2411.04036)|null|[Kimi](https://papers.cool/arxiv/2411.04036)|
| 9|**2024-11-05**|**TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection**|Wei Wu et.al.|[2411.02886](http://arxiv.org/abs/2411.02886)|null|[Kimi](https://papers.cool/arxiv/2411.02886)|
|10|**2024-11-05**|**DroidSpeak: Enhancing Cross-LLM Communication**|Yuhan Liu et.al.|[2411.02820](http://arxiv.org/abs/2411.02820)|null|[Kimi](https://papers.cool/arxiv/2411.02820)|

<p align=right>(<a href=#updated-on-20241115>back to top</a>)</p>

## Early Stopping

|ID|Publish Date|Title|Authors|PDF|Code|Kimi|
|---|---|---|---|---|---|---|
| 1|**2024-11-13**|**Voxeland: Probabilistic Instance-Aware Semantic Mapping with Evidence-based Uncertainty Quantification**|Jose-Luis Matez-Bandera et.al.|[2411.08727](http://arxiv.org/abs/2411.08727)|null|[Kimi](https://papers.cool/arxiv/2411.08727)|
| 2|**2024-11-11**|**The Unreasonable Effectiveness of Monte Carlo Simulations in A/B Testing**|Márton Trencséni et.al.|[2411.06701](http://arxiv.org/abs/2411.06701)|null|[Kimi](https://papers.cool/arxiv/2411.06701)|
| 3|**2024-11-07**|**Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale**|Flavio Di Palo et.al.|[2411.05045](http://arxiv.org/abs/2411.05045)|null|[Kimi](https://papers.cool/arxiv/2411.05045)|
| 4|**2024-11-07**|**LoFi: Scalable Local Image Reconstruction with Implicit Neural Representation**|AmirEhsan Khorashadizadeh et.al.|[2411.04995](http://arxiv.org/abs/2411.04995)|null|[Kimi](https://papers.cool/arxiv/2411.04995)|
| 5|**2024-11-05**|**SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**|Dawei Li et.al.|[2411.03284](http://arxiv.org/abs/2411.03284)|**[link](https://github.com/david-li0406/smoa)**|[Kimi](https://papers.cool/arxiv/2411.03284)|
| 6|**2024-11-06**|**Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression: A Distribution-Free Analysis**|Yingzhen Yang et.al.|[2411.02904](http://arxiv.org/abs/2411.02904)|null|[Kimi](https://papers.cool/arxiv/2411.02904)|
| 7|**2024-11-05**|**Centerness-based Instance-aware Knowledge Distillation with Task-wise Mutual Lifting for Object Detection on Drone Imagery**|Bowei Du et.al.|[2411.02861](http://arxiv.org/abs/2411.02861)|null|[Kimi](https://papers.cool/arxiv/2411.02861)|
| 8|**2024-11-05**|**CE-CoLLM: Efficient and Adaptive Large Language Models Through Cloud-Edge Collaboration**|Hongpeng Jin et.al.|[2411.02829](http://arxiv.org/abs/2411.02829)|null|[Kimi](https://papers.cool/arxiv/2411.02829)|
| 9|**2024-11-06**|**Energy-Aware Dynamic Neural Inference**|Marcello Bullo et.al.|[2411.02471](http://arxiv.org/abs/2411.02471)|null|[Kimi](https://papers.cool/arxiv/2411.02471)|
|10|**2024-11-04**|**DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution**|Yang Yue et.al.|[2411.02359](http://arxiv.org/abs/2411.02359)|**[link](https://github.com/yueyang130/deer-vla)**|[Kimi](https://papers.cool/arxiv/2411.02359)|

<p align=right>(<a href=#updated-on-20241115>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/keyunj/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/keyunj/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/keyunj/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/keyunj/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/keyunj/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/keyunj/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/keyunj/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/keyunj/cv-arxiv-daily/issues

